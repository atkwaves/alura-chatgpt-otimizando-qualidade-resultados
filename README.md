<h1>
    <a href="https://cursos.alura.com.br/course/chatgpt-otimizando-qualidade-resultados">
     <img align="center" width="40px" src="https://www.alura.com.br/assets/api/cursos/chatgpt-otimizando-qualidade-resultados.svg"></a>
    <span>
        Curso de ChatGPT: Otimizando a qualidade dos resultados
    </span>
</h1>

## üî® Objetivos

- Aprender como criar prompts no ChatGPT utilizando diferentes estrat√©gias;
- Utilizar boas pr√°ticas para obter resultados mais confi√°veis;
- Entender como maximizar os resultados obtidos;
- Criar prompts para diferentes aplica√ß√µes;
- Saber como trabalhar com textos longos no ChatGPT;
- Conhecer a OpenAI Playground.

## üìö Aulas

**A01** Criando os primeiros prompts

**A02** Melhorando a confiabilidade dos resultados

**A03** Explorando aplica√ß√µes

**A04** Estrat√©gias para textos longos

## Sum√°rio

- [O que s√£o Prompts?](#o-que-s√£o-prompts)
- [Compreendendo as limita√ß√µes do ChatGPT - Por que nem sempre as respostas s√£o precisas?](#compreendendo-as-limita√ß√µes-do-chatgpt---por-que-nem-sempre-as-respostas-s√£o-precisas)
- [Utilizando diferentes estrat√©gias para criar prompts](#utilizando-diferentes-estrat√©gias-para-criar-prompts)
  - [Prompts de Demonstra√ß√£o](#prompts-de-demonstra√ß√£o) 
  - [Prompts de Conclus√£o](#prompts-de-conclus√£o)
- [Entendendo o que s√£o tokens](#entendendo-o-que-s√£o-tokens)

  

## O que s√£o Prompts?

**`Prompts`** s√£o instru√ß√µes ou entradas fornecidas ao ChatGPT para orientar a gera√ß√£o de texto. Eles s√£o essenciais
para obter respostas relevantes do modelo.

## Compreendendo as limita√ß√µes do ChatGPT - Por que nem sempre as respostas s√£o precisas?

- O modelo pode produzir **respostas plaus√≠veis, mas incorretas**, devido a imprecis√µes nos dados de treinamento. Ele tamb√©m 
√© sens√≠vel a pequenas varia√ß√µes nos prompts e pode ter problemas de prolixidade, usando frases comuns em excesso.

- Tem limita√ß√µes em sua **capacidade de mem√≥ria e contexto**. Ele pode n√£o acessar adequadamente informa√ß√µes ou refer√™ncias 
anteriores na conversa, levando a respostas inconsistentes.

- O modelo pode gerar **respostas imprecisas e tendenciosas** devido aos dados de treinamento e √† forma como foram coletados,
  destacando a import√¢ncia de avaliar criticamente as respostas geradas.

## Utilizando diferentes estrat√©gias para criar prompts

Exploraremos aqui estrat√©gias que aprimoram a efic√°cia dos prompts, impulsionando o desempenho do modelo ChatGPT para 
produzir respostas mais precisas e confi√°veis. Duas abordagens principais se destacam:

###  Prompts de Demonstra√ß√£o
Esses prompts apresentam exemplos ao modelo para indicar o que se espera dele. Esse m√©todo, tamb√©m conhecido como aprendizado
de poucos disparos (Few-Shot learning), permite que o modelo aprenda com apenas alguns exemplos fornecidos no prompt.

Exemplo:

```
Preciso do t√≠tulo para um curso.

Exemplo: Python b√°sico implementando um tradutor de texto
Resposta: Traduzindo qualquer linguagem com Python

Exemplo: Excel para organizar a semana
Resposta: "Resposta do modelo..."
```

### Prompts de Conclus√£o
Esses prompts orientam o modelo a completar uma frase ou padr√£o fornecido. 

Exemplo:

```
"Eu quero/Eu preciso/Me d√™ um curso de Python..."
```

## Entendendo o que s√£o tokens

Os modelos entendem e processam o texto dividindo-o em tokens. Um **`token`** pode ser uma palavra individual, um caractere, 
ou at√© mesmo uma parte de uma palavra. Por exemplo, a frase ‚ÄúHello World!‚Äù teria os seguintes tokens:

![](https://caelum-online-public.s3.amazonaws.com/3146-chatgpt/hello.png)

Temos 3 tokens:
- Hello;
- world;
- Um token para o sinal de exclama√ß√£o.

Enquanto isso, essa mesma frase em portugu√™s, seria dividida da seguinte forma:

![](https://caelum-online-public.s3.amazonaws.com/3146-chatgpt/ola.png)

Nesse caso temos 5 tokens:
- Ol;
- √°;
- mund;
- o;
- Um token para o sinal de exclama√ß√£o.

Com isso, √© poss√≠vel verificar que dependendo do idioma o processo de tokeniza√ß√£o divide as palavras de forma diferente.

> [**Tokenizer**](https://platform.openai.com/tokenizer): Ferramenta da **OpenAI** para checar como um texto se traduz em 
tokens.

O modelo do ChatGPT atribui um valor de representa√ß√£o a cada token, capturando informa√ß√µes contextuais e sem√¢nticas. Essas 
informa√ß√µes sem√¢nticas referem-se ao significado e √† interpreta√ß√£o das palavras, frases ou senten√ßas em um contexto espec√≠fico.

> A sem√¢ntica est√° relacionada ao estudo do significado das palavras e como elas se combinam para formar ideias e express√µes 
mais complexas.

No contexto do processamento de linguagem natural, as informa√ß√µes sem√¢nticas s√£o usadas para capturar o significado e a 
inten√ß√£o subjacentes a uma sequ√™ncia de palavras. Ao entender as informa√ß√µes sem√¢nticas, um modelo de linguagem como o 
ChatGPT pode inferir o contexto e responder de maneira mais precisa.

Ent√£o, os tokens de entrada s√£o passados sequencialmente pelo modelo, permitindo que ele analise o contexto anterior para 
gerar previs√µes sobre o pr√≥ximo token.

> **Observan√ß√£o**: O n√∫mero de tokens de entrada √© limitado para garantir o bom desempenho do modelo e controlar 
os custos computacionais. Se um prompt exceder o limite de tokens permitido, ser√° necess√°rio reduzi-lo ou dividir em partes 
para se adequar ao limite.
